# Асинхронный парсер PEP  (. ❛ ᴗ ❛.)
 ![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

Парсер на базе асинхронного фреймворка [Scrapy](https://github.com/scrapy/scrapy) собирает информацию о PEP с сайта https://peps.python.org

Результат сохраняет в два файла, а именно:

⭕ Собирает список всех PEP c номером, названием и статусом. Сохраняет в csv файл под названием pep_ДатаВремя.

⭕ Посчитывает количество PEP в каждом статусе и общее количество их. Сохраняет в csv файл под названием status_summary_ДатаВремя.

## Запуск проекта

◾ Клонируйте репозиторий и перейти в него

◾ Установите и активируйте виртуальное окружение

◾ Установите зависимости из файла requirements.txt :
```
pip install -r requirements.txt
```
◾ Через командную строку запустите скрипт:
```
scrapy crawl pep
```

## Автор

[Александр Телепин](https://github.com/sasha0090)